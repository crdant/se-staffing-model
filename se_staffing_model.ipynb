{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions Engineering Workload Modeling\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This Jupyter notebook models Solutions Engineering workload based on revenue targets, conversion rates, staffing levels, and activity assumptions. It enables scenario modeling to understand capacity requirements and utilization across different business conditions.\n",
    "\n",
    "### Key Capabilities\n",
    "- **Revenue-Driven Pipeline Modeling**: Calculate required activities from quarterly revenue goals\n",
    "- **Interactive Parameter Controls**: Adjust assumptions and see real-time impact\n",
    "- **Capacity Analysis**: Understand SE team utilization and identify constraints\n",
    "- **Account Management Modeling**: Factor in existing customer meeting requirements\n",
    "- **Strategic Activity Planning**: Allocate time for non-pipeline activities\n",
    "- **Professional Visualizations**: Executive-ready charts and dashboards\n",
    "\n",
    "### Business Applications\n",
    "- Staffing planning and capacity forecasting\n",
    "- Revenue target feasibility analysis\n",
    "- Resource allocation optimization\n",
    "- Scenario planning for different business conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Workload Modeling Approach\n",
    "\n",
    "This model uses a **revenue-driven approach** to calculate SE workload requirements:\n",
    "\n",
    "1. **Start with Revenue Goals**: Quarterly revenue targets drive required new logo counts\n",
    "2. **Work Backwards Through Funnel**: Calculate required demos, evaluations, and meetings\n",
    "3. **Factor in Activity Types**: Different evaluation types require different SE time investments\n",
    "4. **Add Account Management**: Existing customer meetings and onboarding requirements\n",
    "5. **Include Strategic Activities**: Time for customer zero, content creation, and enablement\n",
    "6. **Calculate Utilization**: Compare total workload to available SE capacity\n",
    "\n",
    "### Key Assumptions\n",
    "- **40-hour work week** standard capacity per SE\n",
    "- **Conversion rates** remain consistent across evaluation types\n",
    "- **Account meeting frequencies** based on customer segment strategy\n",
    "- **Strategic activities** distributed between ICs and Directors based on role allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Interactive widgets for parameter controls\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Configure matplotlib for inline display\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seaborn style for professional appearance\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display options for better table formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Configure matplotlib for better chart appearance\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")\n",
    "print(\"‚úÖ Configuration applied\")\n",
    "print(\"üìä Ready to begin workload modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "### üìã Core Sections\n",
    "1. [**Helper Functions Framework**](#helper-functions) - Core calculation functions\n",
    "2. [**Parameter Management**](#parameter-management) - Input parameter definitions and validation\n",
    "3. [**Revenue & Pipeline Calculations**](#revenue-pipeline) - Core funnel math and workload calculations\n",
    "4. [**Account Management Logic**](#account-management) - Meeting frequency and time allocation\n",
    "5. [**Strategic Activities Logic**](#strategic-activities) - Strategic time allocation and distribution\n",
    "\n",
    "### üéõÔ∏è Interactive Interface\n",
    "6. [**Interactive Parameter Controls**](#interactive-controls) - Widget-based parameter input\n",
    "7. [**Real-time Calculations**](#real-time-calculations) - Live calculation updates\n",
    "\n",
    "### üìä Visualization & Results\n",
    "8. [**Core Visualizations**](#core-visualizations) - Essential charts for utilization and capacity\n",
    "9. [**Executive Dashboard**](#executive-dashboard) - Professional dashboard with multiple chart types\n",
    "10. [**Results Summary & Export**](#results-summary) - Executive summary and export capabilities\n",
    "\n",
    "### üîß Testing & Validation\n",
    "11. [**Testing Framework**](#testing) - Comprehensive validation and testing\n",
    "12. [**Usage Examples**](#examples) - Sample scenarios and use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Helper Functions Framework {#helper-functions}\n",
    "\n",
    "*Core calculation functions that will be reused throughout the notebook*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Core helper functions for SE workload modeling calculations\n\ndef calculate_required_new_logos(quarterly_revenue_goal, average_selling_price):\n    \"\"\"\n    Calculate the number of new logos needed to meet quarterly revenue goals.\n    \n    Parameters:\n    - quarterly_revenue_goal (float): Target revenue for the quarter\n    - average_selling_price (float): Average deal size\n    \n    Returns:\n    - float: Number of new logos required\n    \"\"\"\n    if average_selling_price <= 0:\n        raise ValueError(\"Average selling price must be greater than 0\")\n    \n    return quarterly_revenue_goal / average_selling_price\n\n\ndef calculate_weighted_win_rate(eval_mix_percentages, win_rates):\n    \"\"\"\n    Calculate weighted average win rate across all evaluation types.\n    \n    Parameters:\n    - eval_mix_percentages (dict): Percentages for each evaluation type\n    - win_rates (dict): Win rates for each evaluation type\n    \n    Returns:\n    - float: Weighted average win rate (0-1)\n    \"\"\"\n    total_percentage = sum(eval_mix_percentages.values())\n    if abs(total_percentage - 100) > 0.01:  # Allow small floating point errors\n        raise ValueError(f\"Evaluation mix percentages must sum to 100%, got {total_percentage}%\")\n    \n    weighted_sum = 0\n    for eval_type in eval_mix_percentages:\n        if eval_type not in win_rates:\n            raise ValueError(f\"Win rate not provided for evaluation type: {eval_type}\")\n        weighted_sum += (eval_mix_percentages[eval_type] / 100) * (win_rates[eval_type] / 100)\n    \n    return weighted_sum\n\n\ndef calculate_required_activities(new_logos_needed, conversion_rates, eval_mix, win_rates):\n    \"\"\"\n    Work backwards through conversion funnel to calculate required weekly activities.\n    \n    Parameters:\n    - new_logos_needed (float): Required new logos per quarter\n    - conversion_rates (dict): Conversion rates for each funnel stage\n    - eval_mix (dict): Percentage mix of evaluation types\n    - win_rates (dict): Win rates by evaluation type\n    \n    Returns:\n    - dict: Required weekly activities by type\n    \"\"\"\n    # Calculate weighted win rate\n    weighted_win_rate = calculate_weighted_win_rate(eval_mix, win_rates)\n    \n    # Work backwards through funnel (quarterly to weekly)\n    weeks_per_quarter = 13\n    \n    # Required evaluations per quarter\n    required_evaluations_quarterly = new_logos_needed / weighted_win_rate\n    \n    # Required demos per quarter (from tech eval conversion rate)\n    required_demos_quarterly = required_evaluations_quarterly / (conversion_rates['tech_eval_conversion_rate'] / 100)\n    \n    # Required opportunities per quarter (from demo conversion rate)\n    required_opportunities_quarterly = required_demos_quarterly / (conversion_rates['demo_conversion_rate'] / 100)\n    \n    # Required initial meetings per quarter (from opportunity creation rate)\n    required_meetings_quarterly = required_opportunities_quarterly / (conversion_rates['opportunity_creation_rate'] / 100)\n    \n    # Convert to weekly and break down evaluations by type\n    weekly_activities = {\n        'initial_meetings': required_meetings_quarterly / weeks_per_quarter,\n        'demos': required_demos_quarterly / weeks_per_quarter,\n        'total_evaluations': required_evaluations_quarterly / weeks_per_quarter\n    }\n    \n    # Break down evaluations by type\n    for eval_type, percentage in eval_mix.items():\n        eval_key = f\"{eval_type.replace('_percentage', '')}_evaluations\"\n        weekly_activities[eval_key] = weekly_activities['total_evaluations'] * (percentage / 100)\n    \n    return weekly_activities\n\n\ndef calculate_evaluation_workload(weekly_evaluations_by_type, time_per_type):\n    \"\"\"\n    Calculate SE time requirements for different evaluation types.\n    \n    Parameters:\n    - weekly_evaluations_by_type (dict): Weekly evaluation counts by type\n    - time_per_type (dict): Time requirements for each evaluation type\n    \n    Returns:\n    - dict: Weekly hours needed by evaluation type\n    \"\"\"\n    evaluation_hours = {}\n    \n    # Self-guided: ongoing weekly support hours\n    if 'self_guided' in weekly_evaluations_by_type:\n        evaluation_hours['self_guided'] = (weekly_evaluations_by_type['self_guided'] * \n                                         time_per_type['self_guided_support_hours_per_week'])\n    \n    # SE-led: ongoing weekly support hours  \n    if 'se_led' in weekly_evaluations_by_type:\n        evaluation_hours['se_led'] = (weekly_evaluations_by_type['se_led'] * \n                                    time_per_type['se_led_eval_hours_per_week'])\n    \n    # Rapid POV: total hours distributed over evaluation period (assume 2 weeks)\n    if 'rapid_pov' in weekly_evaluations_by_type:\n        rapid_pov_weeks = 2  # Standard duration for rapid POV\n        evaluation_hours['rapid_pov'] = (weekly_evaluations_by_type['rapid_pov'] * \n                                       time_per_type['rapid_pov_total_hours'] / rapid_pov_weeks)\n    \n    # No evaluation type requires no SE time\n    evaluation_hours['no_eval'] = 0\n    \n    return evaluation_hours\n\n\ndef calculate_demo_workload(weekly_demos, demo_time_params):\n    \"\"\"\n    Calculate total demo workload including prep, delivery, and follow-up.\n    \n    Parameters:\n    - weekly_demos (float): Number of demos per week\n    - demo_time_params (dict): Time parameters for demo activities\n    \n    Returns:\n    - float: Total weekly hours for demo activities\n    \"\"\"\n    total_demo_time_per_demo = (demo_time_params['demo_prep_time'] + \n                               demo_time_params['demo_delivery_time'] + \n                               demo_time_params['demo_followup_time'])\n    \n    return weekly_demos * total_demo_time_per_demo\n\n\ndef calculate_meeting_workload(weekly_meetings, meeting_time):\n    \"\"\"\n    Calculate workload for initial meetings including prep time.\n    \n    Parameters:\n    - weekly_meetings (float): Number of initial meetings per week\n    - meeting_time (float): Time per meeting including prep\n    \n    Returns:\n    - float: Total weekly hours for initial meetings\n    \"\"\"\n    return weekly_meetings * meeting_time\n\n\ndef calculate_account_meetings(account_counts, meeting_frequencies):\n    \"\"\"\n    Calculate total meetings per month for existing accounts.\n    \n    Parameters:\n    - account_counts (dict): Number of accounts by segment\n    - meeting_frequencies (dict): Meeting frequency by segment (meetings/month)\n    \n    Returns:\n    - dict: Monthly meetings by account segment\n    \"\"\"\n    monthly_meetings = {}\n    \n    for segment, count in account_counts.items():\n        if segment in meeting_frequencies:\n            if segment == 'retain':\n                # Retain accounts: frequency is \"every X months\", so meetings/month = 1/X\n                meetings_per_month = count / meeting_frequencies[segment]\n            else:\n                # Other segments: frequency is meetings per month\n                meetings_per_month = count * meeting_frequencies[segment]\n            \n            monthly_meetings[segment] = meetings_per_month\n    \n    return monthly_meetings\n\n\ndef calculate_new_logo_onboarding_meetings(new_logos_per_quarter, onboarding_params):\n    \"\"\"\n    Calculate new customer onboarding meeting requirements.\n    \n    Parameters:\n    - new_logos_per_quarter (float): New customers per quarter\n    - onboarding_params (dict): Onboarding meeting parameters\n    \n    Returns:\n    - dict: Monthly onboarding meeting requirements\n    \"\"\"\n    monthly_onboarding = {}\n    \n    # Monthly meetings: 50% of new logos need 6 months of meetings\n    monthly_customers = (new_logos_per_quarter * \n                        (onboarding_params['monthly_onboarding_percentage'] / 100))\n    # 6 months of meetings spread across year = 6/12 = 0.5 factor\n    monthly_onboarding['monthly_meetings'] = monthly_customers * 0.5\n    \n    # Quarterly meetings: 50% of new logos need 4 meetings per year\n    quarterly_customers = (new_logos_per_quarter * \n                          (onboarding_params['quarterly_onboarding_percentage'] / 100))\n    # 4 meetings per year = 4/12 meetings per month\n    monthly_onboarding['quarterly_meetings'] = quarterly_customers * (4/12)\n    \n    return monthly_onboarding\n\n\ndef calculate_account_mgmt_hours(monthly_meetings, meeting_time_params):\n    \"\"\"\n    Convert monthly meetings to weekly SE hours.\n    \n    Parameters:\n    - monthly_meetings (dict): Monthly meeting counts by type\n    - meeting_time_params (dict): Time per meeting including follow-up\n    \n    Returns:\n    - float: Weekly hours for account management\n    \"\"\"\n    total_monthly_meetings = sum(monthly_meetings.values())\n    \n    time_per_meeting = (meeting_time_params['meeting_duration_hours'] + \n                       meeting_time_params['meeting_followup_hours'])\n    \n    monthly_hours = total_monthly_meetings * time_per_meeting\n    \n    # Convert to weekly hours (assume 4.33 weeks per month)\n    weekly_hours = monthly_hours / 4.33\n    \n    return weekly_hours\n\n\ndef calculate_strategic_workload(strategic_params, staffing_config):\n    \"\"\"\n    Calculate strategic activity hours per role.\n    \n    Parameters:\n    - strategic_params (dict): Strategic activity time parameters\n    - staffing_config (dict): Team structure configuration\n    \n    Returns:\n    - dict: Strategic hours by role type\n    \"\"\"\n    # Calculate total strategic hours per week\n    total_strategic_hours = 0\n    \n    # Handle min/max ranges by taking midpoint\n    customer_zero_hours = (strategic_params['customer_zero_hours_min'] + \n                          strategic_params['customer_zero_hours_max']) / 2\n    \n    developer_advocacy_hours = (strategic_params['developer_advocacy_hours_min'] + \n                               strategic_params['developer_advocacy_hours_max']) / 2\n    \n    total_strategic_hours = (customer_zero_hours + \n                           strategic_params['content_creation_hours'] +\n                           strategic_params['sales_enablement_hours'] +\n                           developer_advocacy_hours +\n                           strategic_params['asset_development_hours_avg'])\n    \n    return distribute_strategic_work(total_strategic_hours, \n                                   staffing_config['ic_strategic_percentage'],\n                                   staffing_config['num_ic_ses'],\n                                   staffing_config['num_directors'],\n                                   staffing_config['director_ic_percentage'])\n\n\ndef distribute_strategic_work(total_hours, ic_percentage, num_ics, num_directors, director_ic_percentage):\n    \"\"\"\n    Distribute strategic work between ICs and Directors.\n    \n    Parameters:\n    - total_hours (float): Total strategic hours per week\n    - ic_percentage (float): Percentage allocated to ICs\n    - num_ics (int): Number of IC SEs\n    - num_directors (int): Number of directors\n    - director_ic_percentage (float): Percentage of director time on IC activities\n    \n    Returns:\n    - dict: Strategic hours by role\n    \"\"\"\n    ic_strategic_hours = total_hours * (ic_percentage / 100)\n    director_strategic_hours = total_hours * ((100 - ic_percentage) / 100)\n    \n    # Calculate effective director capacity for strategic work\n    # Directors spend (100 - director_ic_percentage)% on strategic activities\n    director_strategic_capacity_percentage = 100 - director_ic_percentage\n    \n    return {\n        'ic_strategic_hours_per_se': ic_strategic_hours / max(num_ics, 1),\n        'director_strategic_hours_per_director': director_strategic_hours / max(num_directors, 1),\n        'total_ic_strategic_hours': ic_strategic_hours,\n        'total_director_strategic_hours': director_strategic_hours,\n        'director_strategic_capacity_percentage': director_strategic_capacity_percentage\n    }\n\n\ndef validate_percentages_sum_to_100(percentage_dict, tolerance=0.01):\n    \"\"\"\n    Validate that percentages sum to 100%.\n    \n    Parameters:\n    - percentage_dict (dict): Dictionary of percentage values\n    - tolerance (float): Allowed deviation from 100%\n    \n    Returns:\n    - bool: True if valid, False otherwise\n    \"\"\"\n    total = sum(percentage_dict.values())\n    return abs(total - 100) <= tolerance\n\n\ndef calculate_weekly_capacity(num_ses, hours_per_week=40):\n    \"\"\"\n    Calculate total weekly capacity for SE team.\n    \n    Parameters:\n    - num_ses (float): Number of SEs (can be fractional for part-time)\n    - hours_per_week (float): Standard hours per week per SE\n    \n    Returns:\n    - float: Total weekly capacity in hours\n    \"\"\"\n    return num_ses * hours_per_week\n\n\ndef format_hours_for_display(hours):\n    \"\"\"\n    Format hours for user-friendly display.\n    \n    Parameters:\n    - hours (float): Hours to format\n    \n    Returns:\n    - str: Formatted string\n    \"\"\"\n    if hours < 0.1:\n        return \"< 0.1 hrs\"\n    elif hours < 1:\n        return f\"{hours:.1f} hrs\"\n    else:\n        return f\"{hours:.1f} hrs\"\n\n\n# Test helper functions with sample data\ndef test_helper_functions():\n    \"\"\"Test all helper functions with sample inputs to verify correctness.\"\"\"\n    print(\"üß™ Testing Helper Functions\")\n    print(\"=\" * 40)\n    \n    test_results = []\n    \n    try:\n        # Test revenue calculation\n        result = calculate_required_new_logos(2000000, 75000)\n        expected = 26.67\n        assert abs(result - expected) < 0.1, f\"Expected ~{expected}, got {result}\"\n        test_results.append(\"‚úÖ calculate_required_new_logos: Working correctly\")\n        \n        # Test win rate calculation\n        eval_mix = {'self_guided_percentage': 65, 'se_led_percentage': 35}\n        win_rates = {'self_guided_percentage': 35, 'se_led_percentage': 45}\n        result = calculate_weighted_win_rate(eval_mix, win_rates)\n        expected = 0.385  # (0.65 * 0.35) + (0.35 * 0.45)\n        assert abs(result - expected) < 0.01, f\"Expected ~{expected}, got {result}\"\n        test_results.append(\"‚úÖ calculate_weighted_win_rate: Working correctly\")\n        \n        # Test capacity calculation\n        result = calculate_weekly_capacity(2.5, 40)\n        expected = 100\n        assert result == expected, f\"Expected {expected}, got {result}\"\n        test_results.append(\"‚úÖ calculate_weekly_capacity: Working correctly\")\n        \n        # Test percentage validation\n        valid_percentages = {'a': 30, 'b': 70}\n        invalid_percentages = {'a': 30, 'b': 80}\n        assert validate_percentages_sum_to_100(valid_percentages) == True\n        assert validate_percentages_sum_to_100(invalid_percentages) == False\n        test_results.append(\"‚úÖ validate_percentages_sum_to_100: Working correctly\")\n        \n        # Test hours formatting\n        result = format_hours_for_display(12.567)\n        expected = \"12.6 hrs\"\n        assert result == expected, f\"Expected {expected}, got {result}\"\n        test_results.append(\"‚úÖ format_hours_for_display: Working correctly\")\n        \n    except Exception as e:\n        test_results.append(f\"‚ùå Helper function test failed: {str(e)}\")\n    \n    # Display results\n    for result in test_results:\n        print(result)\n    \n    success_count = sum(1 for result in test_results if result.startswith(\"‚úÖ\"))\n    total_count = len(test_results)\n    \n    print(f\"\\nüìä Test Summary: {success_count}/{total_count} tests passed\")\n    \n    if success_count == total_count:\n        print(\"üéâ All helper function tests passed!\")\n        return True\n    else:\n        print(\"‚ö†Ô∏è  Some helper function tests failed.\")\n        return False\n\n# Run tests\ntest_helper_functions()\n\nprint(\"\\n‚úÖ Helper Functions Framework implemented successfully\")\nprint(\"üìù Ready for Step 3: Parameter Management\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Parameter Management {#parameter-management}\n",
    "\n",
    "*Input parameter definitions, default values, and validation rules*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive parameter management system with default values and validation\n\n# ===================================\n# PARAMETER DICTIONARIES WITH DEFAULTS\n# ===================================\n\n# Revenue and Business Target Parameters\nrevenue_params = {\n    'quarterly_revenue_goal': 2000000,      # $2M quarterly revenue target\n    'average_selling_price': 75000          # $75K average deal size\n}\n\n# Sales Conversion Funnel Parameters\nconversion_params = {\n    'opportunity_creation_rate': 50,        # 50% of meetings create opportunities\n    'demo_conversion_rate': 99,             # 99% of opportunities get demos\n    'tech_eval_conversion_rate': 99         # 99% of demos get technical evaluation\n}\n\n# Evaluation Mix Parameters (must sum to 100%)\neval_mix_params = {\n    'self_guided_percentage': 65.5,         # Self-guided evaluations\n    'se_led_percentage': 34.5,              # SE-led evaluations  \n    'rapid_pov_percentage': 1.0,            # Rapid POV evaluations\n    'no_eval_percentage': 0.0               # No evaluation deals\n}\n\n# Win Rate Parameters by Evaluation Type\nwin_rate_params = {\n    'self_guided_win_rate': 35,             # 35% win rate for self-guided\n    'se_led_win_rate': 45,                  # 45% win rate for SE-led\n    'rapid_pov_win_rate': 60,               # 60% win rate for rapid POV\n    'no_eval_win_rate': 10                  # 10% win rate for no evaluation\n}\n\n# Activity Time Requirements (hours)\nactivity_time_params = {\n    'initial_meeting_time': 0.75,           # Initial meeting + prep time\n    'demo_prep_time': 1.0,                  # Demo preparation time\n    'demo_delivery_time': 1.0,              # Demo delivery time  \n    'demo_followup_time': 0.75,             # Demo follow-up time\n    'self_guided_support_hours_per_week': 2.0,     # Weekly support for self-guided\n    'se_led_eval_hours_per_week': 4.0,             # Weekly hours for SE-led evals\n    'rapid_pov_total_hours': 30             # Total hours for rapid POV\n}\n\n# Non-Pipeline Activity Hours (fixed weekly activities per SE)\nfixed_activity_params = {\n    'slack_email_hours': 5.0,               # Slack/email communication\n    'troubleshooting_hours': 3.75,          # Technical troubleshooting\n    'internal_coordination_hours': 7.75,    # Internal meetings/coordination\n    'crm_admin_hours': 2.5                  # CRM and administrative tasks\n}\n\n# Team Structure and Staffing Parameters\nstaffing_params = {\n    'num_ic_ses': 1,                        # Number of IC SEs\n    'num_directors': 1,                     # Number of SE Directors\n    'director_ic_percentage': 50            # % of director time on IC activities\n}\n\n# Strategic Activity Parameters (hours per week per FTE SE)\nstrategic_params = {\n    'customer_zero_hours_min': 2.0,         # Customer zero minimum hours\n    'customer_zero_hours_max': 4.0,         # Customer zero maximum hours\n    'content_creation_hours': 2.0,          # Content creation hours\n    'sales_enablement_hours': 1.0,          # Sales enablement hours\n    'developer_advocacy_hours_min': 1.0,    # Developer advocacy minimum\n    'developer_advocacy_hours_max': 2.0,    # Developer advocacy maximum\n    'asset_development_hours_avg': 1.5,     # Asset development average hours\n    'ic_strategic_percentage': 70           # % of strategic work for ICs vs Directors\n}\n\n# Account Portfolio Parameters\naccount_params = {\n    'strategic_accounts': 3,                # Number of strategic accounts\n    'protect_accounts': 7,                  # Number of protect accounts\n    'growth_accounts': 24,                  # Number of growth accounts\n    'retain_accounts': 59                   # Number of retain accounts\n}\n\n# Meeting Frequency Parameters\nmeeting_frequency_params = {\n    'strategic_meetings_per_month': 1.0,    # Strategic account meetings/month\n    'protect_meetings_per_month': 1.0,      # Protect account meetings/month\n    'growth_meetings_per_month': 1.0,       # Growth account meetings/month\n    'retain_meetings_per_months': 9         # Retain accounts: every X months\n}\n\n# New Customer Onboarding Parameters\nonboarding_params = {\n    'new_logos_per_quarter': 7,             # Expected new logos per quarter\n    'monthly_onboarding_percentage': 50,    # % needing monthly meetings (6 months)\n    'quarterly_onboarding_percentage': 50   # % needing quarterly meetings (4/year)\n}\n\n# Meeting Time Investment Parameters\nmeeting_time_params = {\n    'meeting_duration_hours': 0.5,          # Base meeting duration\n    'meeting_followup_hours': 0.625         # Follow-up time per meeting\n}\n\n# ===================================\n# PARAMETER VALIDATION FUNCTIONS\n# ===================================\n\ndef validate_eval_mix_percentages():\n    \"\"\"Validate that evaluation mix percentages sum to 100%.\"\"\"\n    total = sum(eval_mix_params.values())\n    tolerance = 0.01  # Allow small floating point errors\n    \n    if abs(total - 100) > tolerance:\n        return False, f\\\"Evaluation mix percentages sum to {total:.1f}%, must equal 100%\\\"\n    return True, \\\"Evaluation mix percentages valid\\\"\n\ndef validate_onboarding_percentages():\n    \"\"\"Validate that onboarding percentages sum to ‚â§100%.\"\"\"\n    total = (onboarding_params['monthly_onboarding_percentage'] + \n             onboarding_params['quarterly_onboarding_percentage'])\n    \n    if total > 100:\n        return False, f\\\"Onboarding percentages sum to {total}%, must be ‚â§100%\\\"\n    return True, \\\"Onboarding percentages valid\\\"\n\ndef validate_positive_values():\n    \"\"\"Validate that all time and count parameters are positive.\"\"\"\n    \n    # Check all parameter dictionaries for positive values\n    param_groups = [\n        ('revenue_params', revenue_params),\n        ('conversion_params', conversion_params),\n        ('activity_time_params', activity_time_params),\n        ('fixed_activity_params', fixed_activity_params),\n        ('staffing_params', staffing_params),\n        ('strategic_params', strategic_params),\n        ('account_params', account_params),\n        ('meeting_frequency_params', meeting_frequency_params),\n        ('meeting_time_params', meeting_time_params)\n    ]\n    \n    errors = []\n    \n    for group_name, params in param_groups:\n        for param_name, value in params.items():\n            if value < 0:\n                errors.append(f\\\"{group_name}.{param_name}: {value} (must be ‚â• 0)\\\")\n    \n    if errors:\n        return False, f\\\"Negative values found: {', '.join(errors)}\\\"\n    return True, \\\"All values are positive\\\"\n\ndef validate_percentage_bounds():\n    \"\"\"Validate that all percentage parameters are between 0-100%.\"\"\"\n    \n    # Percentage parameters to check\n    percentage_params = [\n        ('conversion_params.opportunity_creation_rate', conversion_params['opportunity_creation_rate']),\n        ('conversion_params.demo_conversion_rate', conversion_params['demo_conversion_rate']),\n        ('conversion_params.tech_eval_conversion_rate', conversion_params['tech_eval_conversion_rate']),\n        ('eval_mix_params.self_guided_percentage', eval_mix_params['self_guided_percentage']),\n        ('eval_mix_params.se_led_percentage', eval_mix_params['se_led_percentage']),\n        ('eval_mix_params.rapid_pov_percentage', eval_mix_params['rapid_pov_percentage']),\n        ('eval_mix_params.no_eval_percentage', eval_mix_params['no_eval_percentage']),\n        ('win_rate_params.self_guided_win_rate', win_rate_params['self_guided_win_rate']),\n        ('win_rate_params.se_led_win_rate', win_rate_params['se_led_win_rate']),\n        ('win_rate_params.rapid_pov_win_rate', win_rate_params['rapid_pov_win_rate']),\n        ('win_rate_params.no_eval_win_rate', win_rate_params['no_eval_win_rate']),\n        ('staffing_params.director_ic_percentage', staffing_params['director_ic_percentage']),\n        ('strategic_params.ic_strategic_percentage', strategic_params['ic_strategic_percentage']),\n        ('onboarding_params.monthly_onboarding_percentage', onboarding_params['monthly_onboarding_percentage']),\n        ('onboarding_params.quarterly_onboarding_percentage', onboarding_params['quarterly_onboarding_percentage'])\n    ]\n    \n    errors = []\n    \n    for param_name, value in percentage_params:\n        if not (0 <= value <= 100):\n            errors.append(f\\\"{param_name}: {value}% (must be 0-100%)\\\")\n    \n    if errors:\n        return False, f\\\"Invalid percentage values: {', '.join(errors)}\\\"\n    return True, \\\"All percentage values are valid\\\"\n\ndef validate_logical_constraints():\n    \"\"\"Validate logical business constraints.\"\"\"\n    warnings = []\n    errors = []\n    \n    # Check for unrealistic conversion rates\n    if conversion_params['opportunity_creation_rate'] > 80:\n        warnings.append(f\\\"High opportunity creation rate: {conversion_params['opportunity_creation_rate']}%\\\")\n    \n    # Check for unrealistic win rates\n    avg_win_rate = sum(win_rate_params.values()) / len(win_rate_params)\n    if avg_win_rate > 60:\n        warnings.append(f\\\"High average win rate: {avg_win_rate:.1f}%\\\")\n    \n    # Check for unrealistic team structure\n    total_directors = staffing_params['num_directors']\n    total_ics = staffing_params['num_ic_ses']\n    if total_directors > total_ics and total_ics > 0:\n        warnings.append(f\\\"More directors ({total_directors}) than ICs ({total_ics})\\\")\n    \n    # Check for account load reasonableness\n    total_accounts = sum(account_params.values())\n    total_se_capacity = total_ics + total_directors\n    if total_accounts > 0 and total_se_capacity > 0:\n        accounts_per_se = total_accounts / total_se_capacity\n        if accounts_per_se > 50:\n            warnings.append(f\\\"High account load: {accounts_per_se:.1f} accounts per SE\\\")\n    \n    return errors, warnings\n\n# ===================================\n# CENTRAL PARAMETER UPDATE FUNCTION\n# ===================================\n\ndef update_all_parameters():\n    \\\"\\\"\\\"Apply comprehensive validation and return validation results.\\\"\\\"\\\"\n    print(\\\"üîç Validating Parameters\\\")\n    print(\\\"=\\\" * 30)\n    \n    validation_results = []\n    warnings = []\n    \n    # Run all validation checks\n    validations = [\n        validate_eval_mix_percentages(),\n        validate_onboarding_percentages(),\n        validate_positive_values(),\n        validate_percentage_bounds()\n    ]\n    \n    # Check validation results\n    all_valid = True\n    for is_valid, message in validations:\n        if is_valid:\n            validation_results.append(f\\\"‚úÖ {message}\\\")\n        else:\n            validation_results.append(f\\\"‚ùå {message}\\\")\n            all_valid = False\n    \n    # Check logical constraints\n    errors, constraint_warnings = validate_logical_constraints()\n    \n    for error in errors:\n        validation_results.append(f\\\"‚ùå {error}\\\")\n        all_valid = False\n    \n    warnings.extend(constraint_warnings)\n    \n    # Display results\n    for result in validation_results:\n        print(result)\n    \n    if warnings:\n        print(\\\"\\\\n‚ö†Ô∏è  Warnings:\\\")\n        for warning in warnings:\n            print(f\\\"   ‚Ä¢ {warning}\\\")\n    \n    print(f\\\"\\\\nüìä Validation Summary:\\\")\n    if all_valid:\n        print(\\\"‚úÖ All parameters valid and ready for calculations\\\")\n        if warnings:\n            print(f\\\"‚ö†Ô∏è  {len(warnings)} warnings (calculations will proceed)\\\")\n    else:\n        print(\\\"‚ùå Parameter validation failed - please correct errors\\\")\n    \n    return all_valid, warnings\n\n# ===================================\n# PARAMETER SUMMARY DISPLAY\n# ===================================\n\ndef display_parameter_summary():\n    \\\"\\\"\\\"Display a comprehensive summary of all current parameters.\\\"\\\"\\\"\n    print(\\\"üìã Parameter Summary\\\")\n    print(\\\"=\\\" * 50)\n    \n    print(\\\"\\\\nüí∞ Revenue & Business Targets:\\\")\n    print(f\\\"   ‚Ä¢ Quarterly Revenue Goal: ${revenue_params['quarterly_revenue_goal']:,}\\\")\n    print(f\\\"   ‚Ä¢ Average Selling Price: ${revenue_params['average_selling_price']:,}\\\")\n    \n    print(\\\"\\\\nüîÑ Sales Conversion Funnel:\\\")\n    for param, value in conversion_params.items():\n        print(f\\\"   ‚Ä¢ {param.replace('_', ' ').title()}: {value}%\\\")\n    \n    print(\\\"\\\\nüìä Evaluation Mix:\\\")\n    for param, value in eval_mix_params.items():\n        print(f\\\"   ‚Ä¢ {param.replace('_', ' ').title()}: {value}%\\\")\n    \n    print(\\\"\\\\nüéØ Win Rates by Evaluation Type:\\\")\n    for param, value in win_rate_params.items():\n        print(f\\\"   ‚Ä¢ {param.replace('_', ' ').title()}: {value}%\\\")\n    \n    print(\\\"\\\\n‚è∞ Activity Time Requirements:\\\")\n    for param, value in activity_time_params.items():\n        print(f\\\"   ‚Ä¢ {param.replace('_', ' ').title()}: {value} hrs\\\")\n    \n    print(\\\"\\\\nüë• Team Structure:\\\")\n    print(f\\\"   ‚Ä¢ IC SEs: {staffing_params['num_ic_ses']}\\\")\n    print(f\\\"   ‚Ä¢ Directors: {staffing_params['num_directors']}\\\")\n    print(f\\\"   ‚Ä¢ Director IC Time: {staffing_params['director_ic_percentage']}%\\\")\n    \n    print(\\\"\\\\nüè¢ Account Portfolio:\\\")\n    total_accounts = sum(account_params.values())\n    for param, value in account_params.items():\n        percentage = (value / total_accounts * 100) if total_accounts > 0 else 0\n        print(f\\\"   ‚Ä¢ {param.replace('_', ' ').title()}: {value} ({percentage:.1f}%)\\\")\n    \n    print(f\\\"\\\\nüìà Strategic Activities (IC Focus: {strategic_params['ic_strategic_percentage']}%):\\\")\n    print(f\\\"   ‚Ä¢ Customer Zero: {strategic_params['customer_zero_hours_min']}-{strategic_params['customer_zero_hours_max']} hrs/week\\\")\n    print(f\\\"   ‚Ä¢ Content Creation: {strategic_params['content_creation_hours']} hrs/week\\\")\n    print(f\\\"   ‚Ä¢ Sales Enablement: {strategic_params['sales_enablement_hours']} hrs/week\\\")\n    print(f\\\"   ‚Ä¢ Developer Advocacy: {strategic_params['developer_advocacy_hours_min']}-{strategic_params['developer_advocacy_hours_max']} hrs/week\\\")\n    print(f\\\"   ‚Ä¢ Asset Development: {strategic_params['asset_development_hours_avg']} hrs/week (avg)\\\")\n\n# ===================================\n# PARAMETER TESTING\n# ===================================\n\ndef test_parameter_management():\n    \\\"\\\"\\\"Test parameter management system with various scenarios.\\\"\\\"\\\"\n    print(\\\"üß™ Testing Parameter Management System\\\")\n    print(\\\"=\\\" * 45)\n    \n    test_results = []\n    \n    try:\n        # Test 1: Default parameters should be valid\n        is_valid, warnings = update_all_parameters()\n        if is_valid:\n            test_results.append(\\\"‚úÖ Default parameters: Valid\\\")\n        else:\n            test_results.append(\\\"‚ùå Default parameters: Invalid\\\")\n        \n        # Test 2: Test evaluation mix validation\n        original_mix = eval_mix_params.copy()\n        eval_mix_params['self_guided_percentage'] = 50\n        eval_mix_params['se_led_percentage'] = 60  # This should make total > 100%\n        \n        is_valid, message = validate_eval_mix_percentages()\n        if not is_valid:\n            test_results.append(\\\"‚úÖ Evaluation mix validation: Correctly detects invalid sum\\\")\n        else:\n            test_results.append(\\\"‚ùå Evaluation mix validation: Failed to detect invalid sum\\\")\n        \n        # Restore original values\n        eval_mix_params.update(original_mix)\n        \n        # Test 3: Test percentage bounds validation\n        original_conversion = conversion_params['opportunity_creation_rate']\n        conversion_params['opportunity_creation_rate'] = 150  # Invalid percentage\n        \n        is_valid, message = validate_percentage_bounds()\n        if not is_valid:\n            test_results.append(\\\"‚úÖ Percentage bounds validation: Correctly detects out-of-bounds\\\")\n        else:\n            test_results.append(\\\"‚ùå Percentage bounds validation: Failed to detect out-of-bounds\\\")\n        \n        # Restore original value\n        conversion_params['opportunity_creation_rate'] = original_conversion\n        \n        # Test 4: Test positive values validation\n        original_revenue = revenue_params['quarterly_revenue_goal']\n        revenue_params['quarterly_revenue_goal'] = -1000000  # Invalid negative\n        \n        is_valid, message = validate_positive_values()\n        if not is_valid:\n            test_results.append(\\\"‚úÖ Positive values validation: Correctly detects negative values\\\")\n        else:\n            test_results.append(\\\"‚ùå Positive values validation: Failed to detect negative values\\\")\n        \n        # Restore original value\n        revenue_params['quarterly_revenue_goal'] = original_revenue\n        \n    except Exception as e:\n        test_results.append(f\\\"‚ùå Parameter management test failed: {str(e)}\\\")\n    \n    # Display test results\n    print(\\\"\\\\nüìä Test Results:\\\")\n    for result in test_results:\n        print(result)\n    \n    success_count = sum(1 for result in test_results if result.startswith(\\\"‚úÖ\\\"))\n    total_count = len(test_results)\n    \n    print(f\\\"\\\\nüìà Test Summary: {success_count}/{total_count} tests passed\\\")\n    \n    if success_count == total_count:\n        print(\\\"üéâ All parameter management tests passed!\\\")\n        return True\n    else:\n        print(\\\"‚ö†Ô∏è  Some parameter management tests failed.\\\")\n        return False\n\n# ===================================\n# INITIALIZATION\n# ===================================\n\n# Run initial validation and display\nprint(\\\"üîß Parameter Management System Initialized\\\")\nprint(\\\"=\\\" * 50)\n\n# Test the parameter management system\ntest_parameter_management()\n\nprint(\\\"\\\\n\\\" + \\\"=\\\" * 50)\n# Validate current parameters\nis_valid, warnings = update_all_parameters()\n\nif is_valid:\n    print(\\\"\\\\nüìã Current Parameter Configuration:\\\")\n    display_parameter_summary()\n    print(\\\"\\\\n‚úÖ Parameter Management System ready for use\\\")\n    print(\\\"üìù Ready for Step 4: Revenue & Pipeline Calculations\\\")\nelse:\n    print(\\\"\\\\n‚ùå Please correct parameter validation errors before proceeding\\\")\n    print(\\\"üìù Fix errors and re-run parameter validation\\\")\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Revenue & Pipeline Calculations {#revenue-pipeline}\n",
    "\n",
    "*Core funnel math and workload calculations driven by revenue targets*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Revenue & Pipeline Calculation Engine\n# Core business logic for revenue-driven workload modeling\n\n# ===================================\n# PIPELINE CALCULATION ENGINE\n# ===================================\n\ndef run_pipeline_calculations():\n    \"\"\"\n    Execute complete pipeline calculation flow from revenue targets to SE workload.\n    \n    Returns:\n    - dict: Comprehensive pipeline analysis results\n    \"\"\"\n    print(\"üí∞ Running Revenue & Pipeline Calculations\")\n    print(\"=\" * 50)\n    \n    # Step 1: Revenue-to-Activity Calculation\n    print(\"\\\\nüìä Step 1: Revenue Target Analysis\")\n    print(\"-\" * 35)\n    \n    # Calculate required new logos\n    new_logos_needed = calculate_required_new_logos(\n        revenue_params['quarterly_revenue_goal'],\n        revenue_params['average_selling_price']\n    )\n    \n    print(f\"üí∞ Revenue Goal: ${revenue_params['quarterly_revenue_goal']:,}/quarter\")\n    print(f\"üíµ Average Deal Size: ${revenue_params['average_selling_price']:,}\")\n    print(f\"üéØ Required New Logos: {new_logos_needed:.1f}/quarter ({new_logos_needed/13:.1f}/week)\")\n    \n    # Step 2: Pipeline Funnel Calculations\n    print(\"\\\\nüîÑ Step 2: Pipeline Funnel Analysis\")\n    print(\"-\" * 38)\n    \n    # Calculate weighted win rate\n    weighted_win_rate = calculate_weighted_win_rate(eval_mix_params, win_rate_params)\n    \n    print(f\"üìà Weighted Win Rate: {weighted_win_rate:.1%}\")\n    print(\"\\\\nüé≤ Win Rate Breakdown:\")\n    for eval_type, percentage in eval_mix_params.items():\n        win_rate_key = eval_type.replace('_percentage', '_win_rate')\n        if win_rate_key in win_rate_params and percentage > 0:\n            print(f\"   ‚Ä¢ {eval_type.replace('_', ' ').title()}: {percentage:.1f}% of mix @ {win_rate_params[win_rate_key]}% win rate\")\n    \n    # Calculate required activities using helper function\n    weekly_activities = calculate_required_activities(\n        new_logos_needed, \n        conversion_params, \n        eval_mix_params, \n        win_rate_params\n    )\n    \n    print(\"\\\\nüìÖ Required Weekly Activities:\")\n    print(f\"   ‚Ä¢ Initial Meetings: {weekly_activities['initial_meetings']:.1f}/week\")\n    print(f\"   ‚Ä¢ Demos: {weekly_activities['demos']:.1f}/week\")\n    print(f\"   ‚Ä¢ Total Evaluations: {weekly_activities['total_evaluations']:.1f}/week\")\n    \n    # Step 3: Evaluation Workload Breakdown\n    print(\"\\\\nüî¨ Step 3: Evaluation Workload Analysis\")\n    print(\"-\" * 42)\n    \n    # Break down evaluations by type\n    evaluation_breakdown = {}\n    for eval_type, percentage in eval_mix_params.items():\n        if percentage > 0:\n            eval_key = eval_type.replace('_percentage', '')\n            count = weekly_activities['total_evaluations'] * (percentage / 100)\n            evaluation_breakdown[eval_key] = count\n            print(f\"   ‚Ä¢ {eval_type.replace('_', ' ').title()}: {count:.1f}/week\")\n    \n    # Calculate time requirements for each evaluation type\n    evaluation_hours = calculate_evaluation_workload(evaluation_breakdown, activity_time_params)\n    \n    print(\"\\\\n‚è∞ Evaluation Time Requirements (per week):\")\n    total_eval_hours = 0\n    for eval_type, hours in evaluation_hours.items():\n        if hours > 0:\n            print(f\"   ‚Ä¢ {eval_type.replace('_', ' ').title()}: {hours:.1f} hrs\")\n            total_eval_hours += hours\n    print(f\"   ‚Ä¢ Total Evaluation Hours: {total_eval_hours:.1f} hrs/week\")\n    \n    # Step 4: Demo and Meeting Workload\n    print(\"\\\\nüé§ Step 4: Demo & Meeting Workload Analysis\")\n    print(\"-\" * 45)\n    \n    # Calculate demo workload\n    demo_hours = calculate_demo_workload(weekly_activities['demos'], activity_time_params)\n    print(f\"üéØ Demo Workload: {demo_hours:.1f} hrs/week\")\n    print(f\"   ‚Ä¢ Prep: {weekly_activities['demos'] * activity_time_params['demo_prep_time']:.1f} hrs\")\n    print(f\"   ‚Ä¢ Delivery: {weekly_activities['demos'] * activity_time_params['demo_delivery_time']:.1f} hrs\")\n    print(f\"   ‚Ä¢ Follow-up: {weekly_activities['demos'] * activity_time_params['demo_followup_time']:.1f} hrs\")\n    \n    # Calculate meeting workload\n    meeting_hours = calculate_meeting_workload(\n        weekly_activities['initial_meetings'], \n        activity_time_params['initial_meeting_time']\n    )\n    print(f\"ü§ù Initial Meetings: {meeting_hours:.1f} hrs/week ({weekly_activities['initial_meetings']:.1f} meetings)\")\n    \n    # Step 5: Pipeline Activity Summary\n    print(\"\\\\nüìã Step 5: Pipeline Activity Summary\")\n    print(\"-\" * 37)\n    \n    total_pipeline_hours = total_eval_hours + demo_hours + meeting_hours\n    \n    pipeline_summary = {\n        'revenue_goal': revenue_params['quarterly_revenue_goal'],\n        'new_logos_needed': new_logos_needed,\n        'weighted_win_rate': weighted_win_rate,\n        'weekly_activities': weekly_activities,\n        'evaluation_breakdown': evaluation_breakdown,\n        'evaluation_hours': evaluation_hours,\n        'demo_hours': demo_hours,\n        'meeting_hours': meeting_hours,\n        'total_pipeline_hours': total_pipeline_hours\n    }\n    \n    print(f\"üíº Total Pipeline Hours: {total_pipeline_hours:.1f} hrs/week\")\n    print(f\"   ‚Ä¢ Meetings: {meeting_hours:.1f} hrs ({meeting_hours/total_pipeline_hours:.1%})\")\n    print(f\"   ‚Ä¢ Demos: {demo_hours:.1f} hrs ({demo_hours/total_pipeline_hours:.1%})\")\n    print(f\"   ‚Ä¢ Evaluations: {total_eval_hours:.1f} hrs ({total_eval_hours/total_pipeline_hours:.1%})\")\n    \n    return pipeline_summary\n\ndef calculate_pipeline_efficiency_metrics(pipeline_results):\n    \"\"\"\n    Calculate efficiency and performance metrics for the pipeline.\n    \n    Parameters:\n    - pipeline_results (dict): Results from run_pipeline_calculations()\n    \n    Returns:\n    - dict: Efficiency metrics and insights\n    \"\"\"\n    \n    print(\"\\\\nüìä Pipeline Efficiency Analysis\")\n    print(\"=\" * 35)\n    \n    # Calculate key ratios\n    weekly_activities = pipeline_results['weekly_activities']\n    \n    # Conversion efficiency through funnel\n    conversion_efficiency = {\n        'meetings_to_opportunities': conversion_params['opportunity_creation_rate'] / 100,\n        'opportunities_to_demos': conversion_params['demo_conversion_rate'] / 100,\n        'demos_to_evaluations': conversion_params['tech_eval_conversion_rate'] / 100,\n        'evaluations_to_wins': pipeline_results['weighted_win_rate']\n    }\n    \n    # Overall funnel efficiency (meetings to wins)\n    overall_efficiency = 1\n    for stage, rate in conversion_efficiency.items():\n        overall_efficiency *= rate\n    \n    print(f\"üéØ Overall Funnel Efficiency: {overall_efficiency:.1%}\")\n    print(f\"   ‚Ä¢ Meetings ‚Üí Opportunities: {conversion_efficiency['meetings_to_opportunities']:.1%}\")\n    print(f\"   ‚Ä¢ Opportunities ‚Üí Demos: {conversion_efficiency['opportunities_to_demos']:.1%}\")\n    print(f\"   ‚Ä¢ Demos ‚Üí Evaluations: {conversion_efficiency['demos_to_evaluations']:.1%}\")\n    print(f\"   ‚Ä¢ Evaluations ‚Üí Wins: {conversion_efficiency['evaluations_to_wins']:.1%}\")\n    \n    # Time investment per new logo\n    time_per_new_logo = pipeline_results['total_pipeline_hours'] / (pipeline_results['new_logos_needed'] / 13)\n    \n    print(f\"\\\\n‚è±Ô∏è  Time Investment Metrics:\")\n    print(f\"   ‚Ä¢ Hours per New Logo: {time_per_new_logo:.1f} hrs\")\n    print(f\"   ‚Ä¢ Hours per $1M Revenue: {pipeline_results['total_pipeline_hours'] / (revenue_params['quarterly_revenue_goal'] / 1000000 / 13):.1f} hrs/week\")\n    \n    # Activity intensity metrics\n    print(f\"\\\\nüìà Activity Intensity:\")\n    print(f\"   ‚Ä¢ Meetings per Day: {weekly_activities['initial_meetings'] / 5:.1f}\")\n    print(f\"   ‚Ä¢ Demos per Day: {weekly_activities['demos'] / 5:.1f}\")\n    print(f\"   ‚Ä¢ Evaluations per Day: {weekly_activities['total_evaluations'] / 5:.1f}\")\n    \n    efficiency_metrics = {\n        'conversion_efficiency': conversion_efficiency,\n        'overall_efficiency': overall_efficiency,\n        'time_per_new_logo': time_per_new_logo,\n        'hours_per_million_revenue': pipeline_results['total_pipeline_hours'] / (revenue_params['quarterly_revenue_goal'] / 1000000 / 13)\n    }\n    \n    return efficiency_metrics\n\ndef create_pipeline_dataframe(pipeline_results):\n    \"\"\"\n    Create a comprehensive DataFrame summarizing pipeline calculations.\n    \n    Parameters:\n    - pipeline_results (dict): Results from run_pipeline_calculations()\n    \n    Returns:\n    - pd.DataFrame: Structured pipeline data\n    \"\"\"\n    \n    # Create pipeline summary table\n    pipeline_data = []\n    \n    # Revenue and target data\n    pipeline_data.append({\n        'Category': 'Revenue Targets',\n        'Metric': 'Quarterly Revenue Goal',\n        'Weekly Value': revenue_params['quarterly_revenue_goal'] / 13,\n        'Quarterly Value': revenue_params['quarterly_revenue_goal'],\n        'Unit': '$',\n        'Notes': f'${revenue_params[\"quarterly_revenue_goal\"]:,} target'\n    })\n    \n    pipeline_data.append({\n        'Category': 'Revenue Targets', \n        'Metric': 'Required New Logos',\n        'Weekly Value': pipeline_results['new_logos_needed'] / 13,\n        'Quarterly Value': pipeline_results['new_logos_needed'],\n        'Unit': 'logos',\n        'Notes': f'${revenue_params[\"average_selling_price\"]:,} avg deal size'\n    })\n    \n    # Activity requirements\n    for activity, count in pipeline_results['weekly_activities'].items():\n        if activity != 'total_evaluations':  # Skip total since we have breakdown\n            pipeline_data.append({\n                'Category': 'Required Activities',\n                'Metric': activity.replace('_', ' ').title(),\n                'Weekly Value': count,\n                'Quarterly Value': count * 13,\n                'Unit': 'activities',\n                'Notes': f'{count:.1f} per week required'\n            })\n    \n    # Time requirements\n    time_data = [\n        ('Meeting Hours', pipeline_results['meeting_hours'], 'meetings'),\n        ('Demo Hours', pipeline_results['demo_hours'], 'demos'),\n        ('Total Evaluation Hours', sum(pipeline_results['evaluation_hours'].values()), 'evaluations')\n    ]\n    \n    for metric, hours, source in time_data:\n        pipeline_data.append({\n            'Category': 'Time Requirements',\n            'Metric': metric,\n            'Weekly Value': hours,\n            'Quarterly Value': hours * 13,\n            'Unit': 'hours',\n            'Notes': f'From {source}'\n        })\n    \n    # Total pipeline workload\n    pipeline_data.append({\n        'Category': 'Total Workload',\n        'Metric': 'Total Pipeline Hours',\n        'Weekly Value': pipeline_results['total_pipeline_hours'],\n        'Quarterly Value': pipeline_results['total_pipeline_hours'] * 13,\n        'Unit': 'hours',\n        'Notes': 'All pipeline activities combined'\n    })\n    \n    df = pd.DataFrame(pipeline_data)\n    \n    print(\"\\\\nüìä Pipeline Summary Table\")\n    print(\"=\" * 30)\n    \n    # Display formatted table\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.width', None)\n    pd.set_option('display.max_colwidth', 30)\n    \n    # Format numeric columns\n    display_df = df.copy()\n    display_df['Weekly Value'] = display_df['Weekly Value'].apply(lambda x: f'{x:.1f}')\n    display_df['Quarterly Value'] = display_df['Quarterly Value'].apply(lambda x: f'{x:.1f}')\n    \n    print(display_df.to_string(index=False))\n    \n    return df\n\ndef validate_pipeline_calculations(pipeline_results):\n    \"\"\"\n    Validate pipeline calculations for reasonableness and logical consistency.\n    \n    Parameters:\n    - pipeline_results (dict): Results from run_pipeline_calculations()\n    \n    Returns:\n    - tuple: (is_valid, validation_messages)\n    \"\"\"\n    \n    print(\"\\\\nüîç Pipeline Validation\")\n    print(\"=\" * 25)\n    \n    validation_messages = []\n    warnings = []\n    is_valid = True\n    \n    # Check for reasonable activity levels\n    weekly_activities = pipeline_results['weekly_activities']\n    \n    # Validate meeting frequency (should be realistic for SE capacity)\n    if weekly_activities['initial_meetings'] > 50:\n        warnings.append(f\\\"High meeting load: {weekly_activities['initial_meetings']:.1f} meetings/week\\\")\n    \n    if weekly_activities['demos'] > 25:\n        warnings.append(f\\\"High demo load: {weekly_activities['demos']:.1f} demos/week\\\")\n    \n    # Check total hours against reasonable SE capacity\n    total_hours = pipeline_results['total_pipeline_hours']\n    if total_hours > 40:\n        warnings.append(f\\\"Pipeline hours exceed full-time capacity: {total_hours:.1f} hrs/week\\\")\n    \n    # Validate win rate reasonableness\n    if pipeline_results['weighted_win_rate'] > 0.7:\n        warnings.append(f\\\"Very high win rate: {pipeline_results['weighted_win_rate']:.1%}\\\")\n    elif pipeline_results['weighted_win_rate'] < 0.2:\n        warnings.append(f\\\"Very low win rate: {pipeline_results['weighted_win_rate']:.1%}\\\")\n    \n    # Check for mathematical consistency\n    expected_total_evals = sum(pipeline_results['evaluation_breakdown'].values())\n    actual_total_evals = weekly_activities['total_evaluations']\n    \n    if abs(expected_total_evals - actual_total_evals) > 0.01:\n        validation_messages.append(f\\\"‚ùå Evaluation breakdown inconsistency: {expected_total_evals:.2f} vs {actual_total_evals:.2f}\\\")\n        is_valid = False\n    else:\n        validation_messages.append(\\\"‚úÖ Evaluation breakdown mathematically consistent\\\")\n    \n    # Validate conversion rates produce expected results\n    meetings = weekly_activities['initial_meetings']\n    opportunities = meetings * (conversion_params['opportunity_creation_rate'] / 100)\n    expected_demos = opportunities * (conversion_params['demo_conversion_rate'] / 100)\n    \n    if abs(expected_demos - weekly_activities['demos']) > 0.01:\n        validation_messages.append(f\\\"‚ùå Demo calculation inconsistency\\\")\n        is_valid = False\n    else:\n        validation_messages.append(\\\"‚úÖ Funnel calculations mathematically consistent\\\")\n    \n    # Display results\n    for message in validation_messages:\n        print(message)\n    \n    if warnings:\n        print(\\\"\\\\n‚ö†Ô∏è  Warnings:\\\")\n        for warning in warnings:\n            print(f\\\"   ‚Ä¢ {warning}\\\")\n    \n    print(f\\\"\\\\nüìä Validation Summary:\\\")\n    if is_valid:\n        print(\\\"‚úÖ Pipeline calculations validated successfully\\\")\n        if warnings:\n            print(f\\\"‚ö†Ô∏è  {len(warnings)} warnings noted\\\")\n    else:\n        print(\\\"‚ùå Pipeline validation failed - check calculations\\\")\n    \n    return is_valid, validation_messages + warnings\n\n# ===================================\n# SCENARIO ANALYSIS FUNCTIONS\n# ===================================\n\ndef run_sensitivity_analysis():\n    \"\"\"Run sensitivity analysis on key pipeline parameters.\"\"\"\n    \n    print(\"\\\\nüé≠ Pipeline Sensitivity Analysis\")\n    print(\"=\" * 35)\n    \n    base_results = run_pipeline_calculations()\n    base_hours = base_results['total_pipeline_hours']\n    \n    print(f\\\"\\\\nüìä Base Case: {base_hours:.1f} hrs/week\\\")\n    \n    # Test sensitivity to key parameters\n    sensitivities = []\n    \n    # Revenue goal sensitivity\n    original_revenue = revenue_params['quarterly_revenue_goal']\n    for multiplier in [0.5, 0.75, 1.25, 1.5]:\n        revenue_params['quarterly_revenue_goal'] = original_revenue * multiplier\n        test_results = run_pipeline_calculations()\n        change = (test_results['total_pipeline_hours'] - base_hours) / base_hours\n        sensitivities.append({\n            'Parameter': 'Revenue Goal',\n            'Change': f'{multiplier:.0%} of base',\n            'Hours': test_results['total_pipeline_hours'],\n            'Change %': f'{change:+.1%}'\n        })\n    revenue_params['quarterly_revenue_goal'] = original_revenue\n    \n    # Win rate sensitivity  \n    original_win_rates = win_rate_params.copy()\n    for multiplier in [0.8, 0.9, 1.1, 1.2]:\n        for rate_key in win_rate_params:\n            win_rate_params[rate_key] = min(100, original_win_rates[rate_key] * multiplier)\n        test_results = run_pipeline_calculations()\n        change = (test_results['total_pipeline_hours'] - base_hours) / base_hours\n        sensitivities.append({\n            'Parameter': 'Win Rates',\n            'Change': f'{multiplier:.0%} of base',\n            'Hours': test_results['total_pipeline_hours'],\n            'Change %': f'{change:+.1%}'\n        })\n    win_rate_params.update(original_win_rates)\n    \n    # Display sensitivity results\n    sensitivity_df = pd.DataFrame(sensitivities)\n    print(\\\"\\\\nüìà Sensitivity Results:\\\")\n    print(sensitivity_df.to_string(index=False))\n    \n    return sensitivity_df\n\n# ===================================\n# MAIN EXECUTION\n# ===================================\n\n# Run the complete pipeline calculation flow\npipeline_results = run_pipeline_calculations()\n\n# Calculate efficiency metrics\nefficiency_metrics = calculate_pipeline_efficiency_metrics(pipeline_results)\n\n# Create summary DataFrame\npipeline_df = create_pipeline_dataframe(pipeline_results)\n\n# Validate calculations\nis_valid, validation_messages = validate_pipeline_calculations(pipeline_results)\n\n# Store results for use in other sections\nPIPELINE_RESULTS = {\n    'pipeline_summary': pipeline_results,\n    'efficiency_metrics': efficiency_metrics,\n    'pipeline_df': pipeline_df,\n    'validation_status': is_valid,\n    'validation_messages': validation_messages\n}\n\nif is_valid:\n    print(\\\"\\\\n‚úÖ Revenue & Pipeline Calculations completed successfully\\\")\n    print(\\\"üìù Ready for Step 5: Account Management Logic\\\")\n    \n    # Run sensitivity analysis\n    sensitivity_results = run_sensitivity_analysis()\n    PIPELINE_RESULTS['sensitivity_analysis'] = sensitivity_results\n    \nelse:\n    print(\\\"\\\\n‚ùå Pipeline calculations need review before proceeding\\\")\n    print(\\\"üìù Please address validation issues\\\")\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Account Management Logic {#account-management}\n",
    "\n",
    "*Meeting frequency calculations and time allocation for existing customers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for account management logic\n",
    "# Will be implemented in Step 5\n",
    "\n",
    "print(\"üë• Account management logic section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Strategic Activities Logic {#strategic-activities}\n",
    "\n",
    "*Strategic time allocation and distribution between ICs and Directors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for strategic activities logic\n",
    "# Will be implemented in Step 6\n",
    "\n",
    "print(\"üéØ Strategic activities logic section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Interactive Parameter Controls {#interactive-controls}\n",
    "\n",
    "*Widget-based interface for parameter input and real-time updates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for interactive controls\n",
    "# Will be implemented in Steps 7-9\n",
    "\n",
    "print(\"üéõÔ∏è Interactive controls section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Real-time Calculations {#real-time-calculations}\n",
    "\n",
    "*Live calculation updates based on parameter changes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for real-time calculations\n",
    "# Will be implemented in Step 9\n",
    "\n",
    "print(\"‚ö° Real-time calculations section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Core Visualizations {#core-visualizations}\n",
    "\n",
    "*Essential charts for utilization analysis and capacity planning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for core visualizations\n",
    "# Will be implemented in Step 10\n",
    "\n",
    "print(\"üìä Core visualizations section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9. Executive Dashboard {#executive-dashboard}\n",
    "\n",
    "*Professional dashboard with comprehensive business insights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for executive dashboard\n",
    "# Will be implemented in Step 11\n",
    "\n",
    "print(\"üìà Executive dashboard section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 10. Results Summary & Export {#results-summary}\n",
    "\n",
    "*Executive summary generation and export capabilities*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for results summary and export\n",
    "# Will be implemented in Step 12\n",
    "\n",
    "print(\"üìã Results summary & export section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 11. Testing Framework {#testing}\n",
    "\n",
    "*Comprehensive validation and testing of all calculations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for testing framework\n",
    "# Will be implemented throughout all steps\n",
    "\n",
    "print(\"üß™ Testing framework section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 12. Usage Examples {#examples}\n",
    "\n",
    "*Sample scenarios and practical use cases*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for usage examples\n",
    "# Will be implemented in final step\n",
    "\n",
    "print(\"üí° Usage examples section ready for implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Import Verification Test\n",
    "\n",
    "*Basic test to verify all imports are working correctly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all imported libraries\n",
    "def test_imports():\n",
    "    \"\"\"Verify all required libraries are properly imported and functional.\"\"\"\n",
    "    test_results = []\n",
    "    \n",
    "    # Test pandas\n",
    "    try:\n",
    "        test_df = pd.DataFrame({'test': [1, 2, 3]})\n",
    "        assert len(test_df) == 3\n",
    "        test_results.append(\"‚úÖ pandas: Working correctly\")\n",
    "    except Exception as e:\n",
    "        test_results.append(f\"‚ùå pandas: Error - {str(e)}\")\n",
    "    \n",
    "    # Test numpy\n",
    "    try:\n",
    "        test_array = np.array([1, 2, 3])\n",
    "        assert np.sum(test_array) == 6\n",
    "        test_results.append(\"‚úÖ numpy: Working correctly\")\n",
    "    except Exception as e:\n",
    "        test_results.append(f\"‚ùå numpy: Error - {str(e)}\")\n",
    "    \n",
    "    # Test matplotlib\n",
    "    try:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "        ax.plot([1, 2, 3], [1, 4, 2])\n",
    "        plt.close(fig)\n",
    "        test_results.append(\"‚úÖ matplotlib: Working correctly\")\n",
    "    except Exception as e:\n",
    "        test_results.append(f\"‚ùå matplotlib: Error - {str(e)}\")\n",
    "    \n",
    "    # Test seaborn\n",
    "    try:\n",
    "        current_style = sns.axes_style()\n",
    "        assert isinstance(current_style, dict)\n",
    "        test_results.append(\"‚úÖ seaborn: Working correctly\")\n",
    "    except Exception as e:\n",
    "        test_results.append(f\"‚ùå seaborn: Error - {str(e)}\")\n",
    "    \n",
    "    # Test ipywidgets\n",
    "    try:\n",
    "        test_widget = widgets.IntSlider(value=5, min=0, max=10)\n",
    "        assert test_widget.value == 5\n",
    "        test_results.append(\"‚úÖ ipywidgets: Working correctly\")\n",
    "    except Exception as e:\n",
    "        test_results.append(f\"‚ùå ipywidgets: Error - {str(e)}\")\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüîç Import Verification Results:\")\n",
    "    print(\"=\" * 40)\n",
    "    for result in test_results:\n",
    "        print(result)\n",
    "    \n",
    "    # Summary\n",
    "    success_count = sum(1 for result in test_results if result.startswith(\"‚úÖ\"))\n",
    "    total_count = len(test_results)\n",
    "    \n",
    "    print(\"\\nüìä Summary:\")\n",
    "    print(f\"   ‚Ä¢ {success_count}/{total_count} libraries working correctly\")\n",
    "    \n",
    "    if success_count == total_count:\n",
    "        print(\"\\nüéâ All imports successful! Ready to proceed with implementation.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Some imports failed. Please check your environment.\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "test_imports()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "‚úÖ **Step 1 Complete**: Basic notebook structure created with all required sections\n",
    "\n",
    "### Ready for Implementation:\n",
    "- **Step 2**: Helper Functions Framework - Core calculation functions\n",
    "- **Step 3**: Parameter Management - Input parameter definitions and validation\n",
    "\n",
    "### Implementation Notes:\n",
    "- All libraries imported and tested successfully\n",
    "- Professional styling and configuration applied\n",
    "- Clear section structure with table of contents navigation\n",
    "- Placeholder cells ready for modular development\n",
    "- Testing framework initialized\n",
    "\n",
    "**üìù Continue with Step 2 to implement the helper functions framework.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}